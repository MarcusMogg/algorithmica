
当程序员听到 *并行* ，他们大多会想到 *多核并行*，即将一个计算任务划分为多个半独立的线程一起工作来解决问题。

这种类型的并行 通常是为了减少 延时 和实现可伸缩性，但并不改善效率。你可以用并行算法以十倍的速度解决一个大问题，但是要十倍的计算资源。尽管并行硬件越来越充足，并行算法也在逐渐变为一个重要的领域，但是现在，我们要限制我们自己只使用一个CPU。

但在 CPU 核心里已经有另一种并行，你可以免费使用。

## Instruction Pipelining 指令流水线

在执行任何指令前，处理器需要做很多工作：

- 从内存中 **读取** 机器码数据块
- **解码** 并分割指令
- **执行**这些指令, 可能涉及内存指令操作
- 将结果 **写入** 寄存器

整个操作流程很长。一个简单的操作，比如 两个寄存器值相加 可能花费 15-20 个CPU 周期。为了隐藏这个延迟，现代CPU使用 流水线：当一个指令执行到下一个阶段，CPU马上开始执行下一个，而不是等待之前的操作完全完成。

![](img/pipeline.png)


流水线并不消除真正的延迟，而是在功能上让它看起来只有 执行和内存阶段组成。你任然需要花费15～20个周期，但是在你开始执行一个指令序列后只需要花费1次。

考虑到这个，硬件制造商更喜欢使用 *每条指令的周期数 cycles per instruction* (CPI)  而不是 像 指令平均延迟 ，作为CPU设计的主要性能指标。如果我们只考虑有用的指令，这对算法设计来说也是相当好的指标。

一个完美的流水线处理器的CPI应该趋近于1, 但它实际上可以更低，因为我们可以复制 它使得流水线的每个阶段更“宽”，所以同时可以有多条指令执行。缓存和ALU大部分可以共享，因此 这比添加一个完全独立的内核更便宜。这种每个周期可以执行多个指令的CPU架构被称为 超标量 *superscalar* , 大部分现代CPU都是

只有在 指令流包 可以独立处理的逻辑无关的指令组时，你才可以享用 超标量的好处。指令并不总是以最方便的顺序到达，因此，如果有可能，现代CPU会 乱序执行，以提高利用率和减少流水线停顿。这种魔术是如何工作的是一个更高级的讨论主题，但现在，你可以假设 CPU 维护一个（在未来一定距离内）待处理指令的缓冲区，并在计算出其操作数（operands） 的值 并且 有一个可用的执行单元后，立即执行它们。
