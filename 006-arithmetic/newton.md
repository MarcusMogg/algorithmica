

实用算法很少需要达到最大可能的精度。在实际数据中，建模和测量误差通常比舍入浮点数等产生的误差大几个数量级，我们通常非常乐意选择一种以精度换取速度的近似方法。

在本节中，我们将介绍这种近似数值算法中最重要之一：牛顿方法。

## Newton's Method

牛顿方法是一种简单但非常强大的算法，用于查找实数函数的近似根，即以下通用方程的解：

$$
f(x) = 0
$$

关于 $f$ 的唯一假设是至少存在一个根，并且在搜索间隔上是连续且可微分的。也有许多无聊的[边界情况](https://en.wikipedia.org/wiki/Newton%27s_method#Failure_analysis) ,但在实践中一般不会出现，所以我们可以非正式的说 这个函数是“好的”。

该算法的主要思想是从一些初始近似解 $x_0$ 开始，然后通过绘制 $x = x_i$处函数的切线，并设置下一个近似值$x_{i+1}$  等于 x轴于切线的交点。直觉是，如果函数 $f$  是“[好的](https://en.wikipedia.org/wiki/Smoothness)”并且  $x_i$ 已经足够接近根，那么$x_{i+1}$ ​ 就会更加接近。

![](../img/newton.png)


为了得到  $x_n$的切线交点，我们需要将其切线函数等于零：

$$
0 = f(x_i) + (x_{i+1} - x_i) f'(x_i)
$$


$$
x_{i+1} = x_i - \frac{f(x_i)}{f'(x_i)}
$$

牛顿方法非常重要：它是科学和工程中各种优化求解器的基础。

## 平方根

作为一个简单的例子，让我们推导出计算平方根问题的算法：

$$
x = \sqrt n \iff x^2 = n \iff f(x) = x^2 - n = 0
$$

让我们把 $f(x) = x^2 - n$ 代入上面的公式，可以得到以下的更新规则:

$$
x_{i+1} = x_i - \frac{x_i^2 - n}{2 x_i} = \frac{x_i + n / x_i}{2}
$$

在实践中，我们还希望在它足够接近正确答案时立即停止，可以在每次迭代后简单地检查：

```cpp
const double EPS = 1e-9;

double sqrt(double n) {
    double x = 1;
    while (abs(x * x - n) > eps)
        x = (x + n / x) / 2;
    return x;
}
```

该算法收敛于许多函数，尽管它仅对其中的某个子集（例如，凸函数）可靠且可证明地收敛。另一个问题是，如果发生收敛，收敛的速度有多快。

## 收敛速度

Let's run a few iterations of Newton's method to find the square root of $2$, starting with $x_0 = 1$, and check how many digits it got correct after each iteration:

让我们运行牛顿方法的几次迭代，以找到2 的平方根，从$x_0 = 1$ 开始，并检查每次迭代后正确了多少位：

<pre class='center-pre'>
<b>1</b>.0000000000000000000000000000000000000000000000000000000000000
<b>1</b>.5000000000000000000000000000000000000000000000000000000000000
<b>1.41</b>66666666666666666666666666666666666666666666666666666666675
<b>1.41421</b>56862745098039215686274509803921568627450980392156862745
<b>1.41421356237</b>46899106262955788901349101165596221157440445849057
<b>1.41421356237309504880168</b>96235025302436149819257761974284982890
<b>1.41421356237309504880168872420969807856967187537</b>72340015610125
<b>1.4142135623730950488016887242096980785696718753769480731766796</b>
</pre>

仔细观察，我们可以看到每次迭代的准确位数大约翻倍。这种惊人的收敛率并非巧合。

为了定量分析收敛率，我们需要考虑第i 次迭代上的一个小相对误差 $\delta_i$ ，并确定下一次迭代时的误差 $\delta_{i+1}$ 小多少：

$$
|\delta_i| = \frac{|x_n - x|}{x}
$$

可以将 $x_i$ 表示为 $x \cdot (1 + \delta_i)$. 将其代入牛顿迭代，并且两边都除以 $x$ 可以得到：

$$
1 + \delta_{i+1} = \frac{1}{2} (1 + \delta_i + \frac{1}{1 + \delta_i}) = \frac{1}{2} (1 + \delta_i + 1 - \delta_i + \delta_i^2 + o(\delta_i^2)) = 1 + \frac{\delta_i^2}{2} + o(\delta_i^2)
$$

在这里我们使用了 $(1 + \delta_i)^{-1}$ 在 $0$ 处的泰勒展开, 假设误差 $d_i$ 很小 (因为序列收敛,  对于一个足够大的 $n$， $d_i \ll 1$).

重新排练 $\delta_{i+1}$, 我们得到

$$
\delta_{i+1} = \frac{\delta_i^2}{2} + o(\delta_i^2)
$$

这意味着一旦我们接近解决方案，误差在每次迭代中大致平方（和减半）。由于对数 $(- \log_{10} \delta_i)$ 致是答案 $x_i$中准确有效位数的位数, 对相对误差进行平方正好对应于我们观察到的有效位数的两倍。

这被称为二次收敛，实际上，这不仅限于寻找平方根。通过详细的证明留给读者作为练习，可以证明，一般来说

$$
|\delta_{i+1}| = \frac{|f''(x_i)|}{2 \cdot |f'(x_n)|} \cdot \delta_i^2
$$

这导致在一些附加假设下至少二次收敛，即$f'(x) \ne 0$ 而且$f''(x)$ 连续

## Further Reading

[Introduction to numerical methods at MIT](https://ocw.mit.edu/courses/mathematics/18-330-introduction-to-numerical-analysis-spring-2012/lecture-notes/MIT18_330S12_Chapter4.pdf).
